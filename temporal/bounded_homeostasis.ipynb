{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "icml_spike_time_exp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GapeQDQsl-sx"
      },
      "source": [
        "# Bounded Homeostasis to Learn Temporal Targets\n",
        "\n",
        "This notebook replicates the temporal coding experiments in the paper *`The fine line between dead neurons and sparsity in binarized spiking neural networks'*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_R27gZyULBI"
      },
      "source": [
        "!pip install snntorch --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKI4l8OXQxXk"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyB2DosmUNO0"
      },
      "source": [
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import spikegen\n",
        "import snntorch.functional as SF\n",
        "from snntorch import spikeplot as splt\n",
        "from snntorch import utils\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns \n",
        "\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import random\n",
        "from scipy.ndimage.filters import uniform_filter1d\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Utility Functions"
      ],
      "metadata": {
        "id": "34Oz6bzcuCne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "sns.set_theme()\n",
        "\n",
        "def prep_for_plot(mem):\n",
        "  return mem.cpu().detach().squeeze(-1).squeeze(-1)\n",
        "\n",
        "def plot_quadrant(mem, spk_out, target_mem, spk_target, y1, y2, threshold=1, save=False, epoch1 = 1, epoch2=25, epoch3=100, fill=True):\n",
        "  # Generate Plots\n",
        "  gs = gridspec.GridSpec(2, 4, height_ratios=[1, 0.07])\n",
        "  fig = plt.figure(figsize=(12,4.5),)\n",
        "  ax1 = plt.subplot(gs[0,0])\n",
        "  ax2 = plt.subplot(gs[1,0])\n",
        "  ax3 = plt.subplot(gs[0,1])\n",
        "  ax4 = plt.subplot(gs[1,1])\n",
        "  ax5 = plt.subplot(gs[0,2])\n",
        "  ax6 = plt.subplot(gs[1,2])\n",
        "  ax7 = plt.subplot(gs[0,3])\n",
        "  ax8 = plt.subplot(gs[1,3])\n",
        "\n",
        "  mem = prep_for_plot(mem)\n",
        "  spk_out = prep_for_plot(spk_out)\n",
        "  target_mem = prep_for_plot(target_mem)\n",
        "  epoch1_str = str(epoch1)\n",
        "  epoch2_str = str(epoch2)\n",
        "  epoch3_str = str(epoch3)\n",
        "\n",
        "  fontsize = 25\n",
        "\n",
        "  ########### TARGET ########\n",
        "    # Plot membrane potential\n",
        "  ax1.plot(target_mem)\n",
        "  ax1.set_ylim([y1, y2]) # 0.1, 1.3\n",
        "  ax1.set_ylabel(\"$u$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax1.axhline(y=threshold, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "  ax1.set_yticks([])\n",
        "  ax1.set_xticks([])\n",
        "  ax1.set_title(\"Target\",fontsize=fontsize, fontweight='bold')\n",
        "  # plt.xlabel(\"Time\") \n",
        "\n",
        "  # Plot output spike using spikeplot\n",
        "  splt.raster(spk_target, ax2, s=250, c=\"black\", marker=\".\")\n",
        "  ax2.set_ylabel(\"$z$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax2.set_xlabel(\"$t$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax2.set_yticks([]) \n",
        "  ax2.set_xticks([])\n",
        "  ax2.set_xlim(0, 100)\n",
        "\n",
        "  ############## EPOCH 1 ########\n",
        "\n",
        "  # Plot membrane potential\n",
        "  ax3.plot(mem[epoch1])\n",
        "  ax3.set_ylim([y1, y2]) # 0.1, 1.3\n",
        "  ax3.axhline(y=threshold, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "  ax3.set_yticks([])\n",
        "  ax3.set_xticks([])\n",
        "  ax3.set_title(\"$\\gamma =$\" + epoch1_str ,fontsize=fontsize, fontweight='bold')\n",
        "  # plt.xlabel(\"Time\") \n",
        "\n",
        "  # Plot output spike using spikeplot\n",
        "  splt.raster(spk_out[epoch1], ax4, s=250, c=\"black\", marker=\".\")\n",
        "  # ax4.set_ylabel(\"$z^{~j}_t$\", fontsize=fontsize, fontweight='bold') \n",
        "  ax4.set_xlabel(\"$t$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax4.set_yticks([]) \n",
        "  ax4.set_xticks([])\n",
        "  ax4.set_xlim(0, 100)\n",
        "\n",
        "  ############## EPOCH 100 ########\n",
        "\n",
        "  # Plot membrane potential\n",
        "  ax5.plot(mem[epoch2])\n",
        "  ax5.set_ylim([y1, y2]) # 0.1, 1.3\n",
        "  # ax5.set_ylabel(\"$u^{~j}_t$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax5.axhline(y=threshold, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "  ax5.set_yticks([])\n",
        "  ax5.set_xticks([]) \n",
        "  ax5.set_title(\"$\\gamma =$\" + epoch2_str,fontsize=fontsize, fontweight='bold')\n",
        "  # plt.xlabel(\"Time\") \n",
        "\n",
        "  # Plot output spike using spikeplot\n",
        "  splt.raster(spk_out[epoch2], ax6, s=250, c=\"black\", marker=\".\")\n",
        "  # ax6.set_ylabel(\"$z^{~j}_t$\", fontsize=fontsize, fontweight='bold') \n",
        "  ax6.set_xlabel(\"$t$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax6.set_yticks([]) \n",
        "  ax6.set_xticks([])\n",
        "  ax6.set_xlim(0, 100)\n",
        "\n",
        "  ########## EPOCH 100 ##############\n",
        "  # Plot membrane potential\n",
        "  ax7.plot(mem[epoch3])\n",
        "  ax7.set_ylim([y1, y2]) # 0.1, 1.3\n",
        "  # ax7.set_ylabel(\"$u^{~j}_t$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax7.axhline(y=threshold, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "  ax7.set_yticks([])\n",
        "  ax7.set_xticks([])\n",
        "  ax7.set_title(\"$\\gamma =$\" + epoch3_str,fontsize=fontsize, fontweight='bold')\n",
        "  # plt.xlabel(\"Time\") \n",
        "\n",
        "  # Plot output spike using spikeplot\n",
        "  splt.raster(spk_out[epoch3], ax8, s=250, c=\"black\", marker=\".\")\n",
        "  # ax8.set_ylabel(\"$z^{~j}_t$\", fontsize=fontsize, fontweight='bold') \n",
        "  ax8.set_xlabel(\"$t$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax8.set_yticks([]) \n",
        "  ax8.set_xticks([])\n",
        "  ax8.set_xlim(0, 100)\n",
        "  \n",
        "  fig.tight_layout()\n",
        "  plt.subplots_adjust(\n",
        "                    # left=0.125,\n",
        "                    # bottom=0.1, \n",
        "                    # right=0.9, \n",
        "                    # top=0.9, \n",
        "                    wspace=0.01, \n",
        "                    hspace=0.)\n",
        "  \n",
        "  if fill:\n",
        "    ax1.fill_between(x, target_mem, step=\"pre\", alpha=0.4, color='tab:blue')\n",
        "    ax3.fill_between(x, mem[epoch1], step=\"pre\", alpha=0.4, color='tab:blue')\n",
        "    ax5.fill_between(x, mem[epoch2], step=\"pre\", alpha=0.4, color='tab:blue')\n",
        "    ax7.fill_between(x, mem[epoch3], step=\"pre\", alpha=0.4, color='tab:blue')\n",
        "\n",
        "  fig1 = plt.gcf()\n",
        "  if save:\n",
        "    fig1.savefig(save, dpi=600)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_quadrant_tha(mem, spk_out, target_mem, spk_target, y1, y2, \n",
        "                      threshold=[1, 1, 1], save=False, epoch1 = 1, epoch2=25, \n",
        "                      epoch3=100, fill=True):\n",
        "  # Generate Plots\n",
        "  gs = gridspec.GridSpec(2, 4, height_ratios=[1, 0.07])\n",
        "  fig = plt.figure(figsize=(12,4.5),)\n",
        "  ax1 = plt.subplot(gs[0,0])\n",
        "  ax2 = plt.subplot(gs[1,0])\n",
        "  ax3 = plt.subplot(gs[0,1])\n",
        "  ax4 = plt.subplot(gs[1,1])\n",
        "  ax5 = plt.subplot(gs[0,2])\n",
        "  ax6 = plt.subplot(gs[1,2])\n",
        "  ax7 = plt.subplot(gs[0,3])\n",
        "  ax8 = plt.subplot(gs[1,3])\n",
        "\n",
        "  mem = prep_for_plot(mem)\n",
        "  spk_out = prep_for_plot(spk_out)\n",
        "  target_mem = prep_for_plot(target_mem)\n",
        "  epoch1_str = str(epoch1)\n",
        "  epoch2_str = str(epoch2)\n",
        "  epoch3_str = str(epoch3)\n",
        "\n",
        "  fontsize = 25\n",
        "\n",
        "  ########### TARGET ########\n",
        "    # Plot membrane potential\n",
        "  ax1.plot(target_mem)\n",
        "  ax1.set_ylim([y1, y2]) # 0.1, 1.3\n",
        "  ax1.set_ylabel(\"$u$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax1.axhline(y=threshold[999], alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "  ax1.set_yticks([])\n",
        "  ax1.set_xticks([])\n",
        "  ax1.set_title(\"Target\",fontsize=fontsize, fontweight='bold')\n",
        "  # plt.xlabel(\"Time\") \n",
        "\n",
        "  # Plot output spike using spikeplot\n",
        "  splt.raster(spk_target, ax2, s=250, c=\"black\", marker=\".\")\n",
        "  ax2.set_ylabel(\"$z$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax2.set_xlabel(\"$t$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax2.set_yticks([]) \n",
        "  ax2.set_xticks([])\n",
        "  ax2.set_xlim(0, 100)\n",
        "\n",
        "  ############## EPOCH 1 ########\n",
        "\n",
        "  # Plot membrane potential\n",
        "  ax3.plot(mem[epoch1])\n",
        "  ax3.set_ylim([y1, y2]) # 0.1, 1.3\n",
        "  ax3.axhline(y=threshold[epoch1], alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "  ax3.set_yticks([])\n",
        "  ax3.set_xticks([])\n",
        "  ax3.set_title(\"$\\gamma =$\" + epoch1_str ,fontsize=fontsize, fontweight='bold')\n",
        "  # plt.xlabel(\"Time\") \n",
        "\n",
        "  # Plot output spike using spikeplot\n",
        "  splt.raster(spk_out[epoch1], ax4, s=250, c=\"black\", marker=\".\")\n",
        "  # ax4.set_ylabel(\"$z^{~j}_t$\", fontsize=fontsize, fontweight='bold') \n",
        "  ax4.set_xlabel(\"$t$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax4.set_yticks([]) \n",
        "  ax4.set_xticks([])\n",
        "  ax4.set_xlim(0, 100)\n",
        "\n",
        "  ############## EPOCH 100 ########\n",
        "\n",
        "  # Plot membrane potential\n",
        "  ax5.plot(mem[epoch2])\n",
        "  ax5.set_ylim([y1, y2]) # 0.1, 1.3\n",
        "  # ax5.set_ylabel(\"$u^{~j}_t$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax5.axhline(y=threshold[epoch2], alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "  ax5.set_yticks([])\n",
        "  ax5.set_xticks([]) \n",
        "  ax5.set_title(\"$\\gamma =$\" + epoch2_str,fontsize=fontsize, fontweight='bold')\n",
        "  # plt.xlabel(\"Time\") \n",
        "\n",
        "  # Plot output spike using spikeplot\n",
        "  splt.raster(spk_out[epoch2], ax6, s=250, c=\"black\", marker=\".\")\n",
        "  # ax6.set_ylabel(\"$z^{~j}_t$\", fontsize=fontsize, fontweight='bold') \n",
        "  ax6.set_xlabel(\"$t$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax6.set_yticks([]) \n",
        "  ax6.set_xticks([])\n",
        "  ax6.set_xlim(0, 100)\n",
        "\n",
        "  ########## EPOCH 100 ##############\n",
        "  # Plot membrane potential\n",
        "  ax7.plot(mem[epoch3])\n",
        "  ax7.set_ylim([y1, y2]) # 0.1, 1.3\n",
        "  # ax7.set_ylabel(\"$u^{~j}_t$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax7.axhline(y=threshold[epoch3], alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "  ax7.set_yticks([])\n",
        "  ax7.set_xticks([])\n",
        "  ax7.set_title(\"$\\gamma =$\" + epoch3_str,fontsize=fontsize, fontweight='bold')\n",
        "  # plt.xlabel(\"Time\") \n",
        "\n",
        "  # Plot output spike using spikeplot\n",
        "  splt.raster(spk_out[epoch3], ax8, s=250, c=\"black\", marker=\".\")\n",
        "  # ax8.set_ylabel(\"$z^{~j}_t$\", fontsize=fontsize, fontweight='bold') \n",
        "  ax8.set_xlabel(\"$t$\", fontsize=fontsize, fontweight='bold')\n",
        "  ax8.set_yticks([]) \n",
        "  ax8.set_xticks([])\n",
        "  ax8.set_xlim(0, 100)\n",
        "  \n",
        "  fig.tight_layout()\n",
        "  plt.subplots_adjust(\n",
        "                    # left=0.125,\n",
        "                    # bottom=0.1, \n",
        "                    # right=0.9, \n",
        "                    # top=0.9, \n",
        "                    wspace=0.01, \n",
        "                    hspace=0.)\n",
        "  \n",
        "  if fill:\n",
        "    ax1.fill_between(x, target_mem, step=\"pre\", alpha=0.4, color='tab:blue')\n",
        "    ax3.fill_between(x, mem[epoch1], step=\"pre\", alpha=0.4, color='tab:blue')\n",
        "    ax5.fill_between(x, mem[epoch2], step=\"pre\", alpha=0.4, color='tab:blue')\n",
        "    ax7.fill_between(x, mem[epoch3], step=\"pre\", alpha=0.4, color='tab:blue')\n",
        "\n",
        "  fig1 = plt.gcf()\n",
        "  if save:\n",
        "    fig1.savefig(save, dpi=600)\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RERn5ncNBF2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1svHV-viQ_Ll"
      },
      "source": [
        "# 1. High Precision Testing\n",
        "##  1.1 Choose some random hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izqVw9L4UaWx"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "dtype = torch.float\n",
        "num_steps = 100\n",
        "num_inputs = 100\n",
        "num_hidden = 1000\n",
        "batch_size = 1\n",
        "beta=0.6\n",
        "spike_time = 75\n",
        "\n",
        "loss_fn = nn.MSELoss() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_all_seeds(seed=0):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_all_seeds()"
      ],
      "metadata": {
        "id": "1npF4uSpAbLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rQJ71afRqwo"
      },
      "source": [
        "## 1.2 Generate Random Inputs and Membrane Trace Target\n",
        "* The random inputs will be fed to the network\n",
        "* The output neuron will be trained to replicate the evolution of the membrane trace generated below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGXVx6u-UsuL"
      },
      "source": [
        "input_prob = torch.rand(num_steps, batch_size, num_inputs).to(device)\n",
        "input_data = spikegen.rate(input_prob, time_var_input=True)\n",
        "target_mem = spikegen.targets_latency(torch.zeros(1, dtype=dtype, device=device), num_classes=1, first_spike_time=75, on_target=1.05, num_steps=100, interpolate=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MUE72R0bSSU"
      },
      "source": [
        "# membrane trace target: Threshold=1\n",
        "splt.traces(target_mem, spk=False, dim=(1,1), spk_height=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "638dTiPNRzuc"
      },
      "source": [
        "## 1.3 Define network\n",
        "100-1000-1 Dense Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k42uNpyxzsCb"
      },
      "source": [
        "net = nn.Sequential(\n",
        "    nn.Linear(num_inputs, num_hidden),\n",
        "    snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=5), init_hidden=True),\n",
        "    nn.Linear(num_hidden, 1),\n",
        "    snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=5), init_hidden=True, output=True)\n",
        ").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBLjAshUR1SM"
      },
      "source": [
        "## 1.4 High-precision training loop\n",
        "Start with high precision weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3fkyBYxU_h8"
      },
      "source": [
        "# optimizer = torch.optim.Adam(net.parameters(), lr=1e-4, betas=(0.9, 0.999)) \n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)\n",
        "num_epochs = 1000\n",
        "\n",
        "mem_tot = []\n",
        "spk_tot = []\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  mem_rec = []\n",
        "  spk_rec = []\n",
        "\n",
        "  utils.reset(net)\n",
        "\n",
        "  for step in range(num_steps):\n",
        "    spk, mem = net(input_data[step])\n",
        "    mem_rec.append(mem)\n",
        "    spk_rec.append(spk)\n",
        "\n",
        "  mem_rec = torch.stack(mem_rec)\n",
        "  mem_tot.append(mem_rec)\n",
        "\n",
        "  spk_rec = torch.stack(spk_rec)\n",
        "  spk_tot.append(spk_rec)\n",
        "\n",
        "  # loss = loss_fn(targets_spike, mem_rec) + 2*loss_fn(targets_spike[75], mem_rec[75])+ 5e-1*sum(spk_rec)  # full trace \n",
        "  loss = loss_fn(target_mem, mem_rec) # + 2 * loss_fn(targets_spike[75], mem_rec[75]) # + 0*(torch.exp(sum(spk_rec))-1)\n",
        "\n",
        "  # clear previously stored gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # calculate the gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # weight update\n",
        "  optimizer.step()\n",
        "\n",
        "mem_tot = torch.stack(mem_tot)\n",
        "spk_tot = torch.stack(spk_tot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Plot Membrane Potential\n",
        "$\\gamma$ refers to the training iteration."
      ],
      "metadata": {
        "id": "aa6ioKwHuG9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_quadrant(mem_tot, spk_tot, target_mem, spk_target, -0.1, 1.2, threshold=1, save=\"spk_time_flt.png\", epoch1=1, epoch2=100, epoch3=500, fill=True) # save=\"spk_time_flt.png\""
      ],
      "metadata": {
        "id": "ClAhLranCClW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL3ywHTumXY7"
      },
      "source": [
        "## 1.6 Evolution of membrane potential over training epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEyHUZD5IcUU"
      },
      "source": [
        "threshold = 1\n",
        "fig, ax = plt.subplots()\n",
        "line, = ax.plot([])   # A tuple unpacking to unpack the only plot\n",
        "x = np.arange(0, 100, 1) \n",
        "\n",
        "ax.set_xlim(0, num_steps)\n",
        "ax.set_ylim(-0.5, 1.5)\n",
        "time_text = ax.text(0.02, 0.98,'',horizontalalignment='left',\n",
        "                    verticalalignment='top', transform=ax.transAxes, size='large')\n",
        "\n",
        "ax.set_ylabel('Membrane Potential ($u$)')\n",
        "ax.set_xlabel('Time Steps')\n",
        "ax.plot(target_mem[:, 0, 0].cpu().detach().numpy(), label='Target', linestyle='dashed')\n",
        "ax.axhline(y=threshold, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "\n",
        "\n",
        "def animate(frame_num):\n",
        "    line.set_data(x, mem_tot[frame_num, x, 0,0].cpu().detach().numpy())\n",
        "    time_text.set_text(f'Epoch: {frame_num}')\n",
        "\n",
        "    # ax.plot([], [], ' ', label=str(frame_num))\n",
        "    # ax.legend(loc='upper right')\n",
        "    return (line, time_text)\n",
        "\n",
        "anim = FuncAnimation(fig, animate, frames=num_epochs, interval=30)\n",
        "anim.save('spk_time_flt.mp4', fps=25, extra_args=['-vcodec', 'libx264'], dpi=300)\n",
        "\n",
        "video = anim.to_html5_video()\n",
        "html = display.HTML(video)\n",
        "display.display(html)\n",
        "plt.close()                   # avoid plotting a spare static plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4RqawaA4BbU"
      },
      "source": [
        "# 2. Binarized Spike Timing: Threshold=1\n",
        "The high precision simulation does a good job of tracking the desired membrane potential. There is instability when a spike occurs because of the discontinuous reset: when the neuron is reset, the weights try to offset the sudden change by increasing weights.\n",
        "\n",
        "Now, let's test out binarized spiking neural nets. \n",
        "Before introducing threshold annealing, we will apply a threshold of $\\theta=1$ to all neurons. The input of each axon can only ever be +1 or -1. \n",
        "We can expect the outcome to be extremely unstable.\n",
        "\n",
        "## 2.1 Binarized Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dZkN83RbDP0"
      },
      "source": [
        "class BinaryLinear(nn.Linear):\n",
        "    def forward(self, input):\n",
        "        binary_weight = binarize(self.weight)\n",
        "        if self.bias is None:\n",
        "            return F.linear(input, binary_weight)\n",
        "        else:\n",
        "            return F.linear(input, binary_weight, self.bias)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Glorot initialization\n",
        "        in_features, out_features = self.weight.size()\n",
        "        stdv = math.sqrt(1.5 / (in_features + out_features))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.zero_()\n",
        "\n",
        "        self.weight.lr_scale = 1. / stdv\n",
        "\n",
        "\n",
        "class BinarizeF(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        output = input.new(input.size())\n",
        "        output[input >= 0] = 1\n",
        "        output[input < 0] = -1\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        grad_input = grad_output.clone()\n",
        "        return grad_input\n",
        "\n",
        "# aliases\n",
        "binarize = BinarizeF.apply"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ_v2xDcU6Hh"
      },
      "source": [
        "## 2.2 Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1UYIj62U3Vm"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "dtype = torch.float\n",
        "num_steps = 100\n",
        "num_inputs = 100\n",
        "num_hidden = 1000\n",
        "batch_size = 1\n",
        "beta=0.15 \n",
        "\n",
        "loss_fn = nn.MSELoss() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbfDFqYJm-95"
      },
      "source": [
        "## 2.3 Network Definition\n",
        "Same architecture will be used all throughout: 100-1000-1 Dense Layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf1uJDT6dbst"
      },
      "source": [
        "b_net = nn.Sequential(\n",
        "    BinaryLinear(num_inputs, num_hidden),\n",
        "    snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=5), init_hidden=True),\n",
        "    BinaryLinear(num_hidden, 1),\n",
        "    snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=5), init_hidden=True, output=True)\n",
        ").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZHfDW88nAx5"
      },
      "source": [
        "## 2.4 Binarized Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlUf-mt28z0h"
      },
      "source": [
        "optimizer = torch.optim.SGD(b_net.parameters(), lr=1e-3, momentum=0.9)\n",
        "num_epochs = 1000\n",
        "mem_tot_bin = []\n",
        "spk_tot_bin = []\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  mem_rec = []\n",
        "  spk_rec = []\n",
        "\n",
        "  utils.reset(net)\n",
        "\n",
        "  for step in range(num_steps):\n",
        "    spk, mem = b_net(input_data[step])\n",
        "    mem_rec.append(mem)\n",
        "    spk_rec.append(spk)\n",
        "\n",
        "  spk_rec = torch.stack(spk_rec)\n",
        "  mem_rec = torch.stack(mem_rec)\n",
        "  mem_tot_bin.append(mem_rec)\n",
        "  spk_tot_bin.append(spk_rec)\n",
        "\n",
        "  loss = loss_fn(target_mem, mem_rec)\n",
        "\n",
        "  # clear previously stored gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # calculate the gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # weight update\n",
        "  optimizer.step()\n",
        "\n",
        "mem_tot_bin = torch.stack(mem_tot_bin)\n",
        "spk_tot_bin = torch.stack(spk_tot_bin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Plot Membrane Potential"
      ],
      "metadata": {
        "id": "iUHLpcIdu4wJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_quadrant(mem_tot_bin, spk_tot_bin, target_mem, spk_target, -0.1, 1.2, threshold=1, save='spk_time_bin.png', epoch1=0, epoch2=75, epoch3=750, fill=True) # save=\"spk_time_flt.png\""
      ],
      "metadata": {
        "id": "PYewBqdZgWa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, this doesn't look great. \n",
        "This somewhat resembles the pathological case described in section 2 of the paper, where BSNNs struggle to incorporate both memory dynamics and spike propagation. I.e., no smooth memory dynamics are visible above."
      ],
      "metadata": {
        "id": "7IB8TGFWu68L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8orKC1dntVS"
      },
      "source": [
        "## 2.6 Evolution of membrane trace over training epochs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 1\n",
        "fig, ax = plt.subplots()\n",
        "line, = ax.plot([])   # A tuple unpacking to unpack the only plot\n",
        "x = np.arange(0, 100, 1) \n",
        "\n",
        "ax.set_xlim(0, num_steps)\n",
        "ax.set_ylim(-0.5, 1.5)\n",
        "time_text = ax.text(0.02, 0.98,'',horizontalalignment='left',\n",
        "                    verticalalignment='top', transform=ax.transAxes, size='large')\n",
        "\n",
        "ax.set_ylabel('Membrane Potential ($u$)')\n",
        "ax.set_xlabel('Time Steps')\n",
        "ax.plot(target_mem[:, 0, 0].cpu().detach().numpy(), label='Target', linestyle='dashed')\n",
        "ax.axhline(y=threshold, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "\n",
        "\n",
        "def animate(frame_num):\n",
        "    line.set_data(x, mem_tot_bin[frame_num, x, 0,0].cpu().detach().numpy())\n",
        "    time_text.set_text(f'Epoch: {frame_num}')\n",
        "    return (line, time_text)\n",
        "\n",
        "anim = FuncAnimation(fig, animate, frames=num_epochs, interval=30)\n",
        "anim.save('spk_time_bin.mp4', fps=25, extra_args=['-vcodec', 'libx264'], dpi=300)\n",
        "\n",
        "video = anim.to_html5_video()\n",
        "html = display.HTML(video)\n",
        "display.display(html)\n",
        "plt.close()                   # avoid plotting a spare static plot"
      ],
      "metadata": {
        "id": "5OWG-Vzqhonn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8IpqgZvoeYT"
      },
      "source": [
        "## 2.7 Moving Average\n",
        "Perhaps we will see better results if we take the moving average of the membrane potential (over epochs)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 1\n",
        "fig, ax = plt.subplots()\n",
        "line, = ax.plot([])   # A tuple unpacking to unpack the only plot\n",
        "x = np.arange(0, 100, 1)\n",
        "\n",
        "N = 5 # size of filter\n",
        "mem_avg_bin = uniform_filter1d(mem_tot_bin.cpu().detach(), size=N, axis=1)\n",
        "\n",
        "ax.set_xlim(0, num_steps)\n",
        "ax.set_ylim(-0.5, 1.5)\n",
        "time_text = ax.text(0.02, 0.98,'',horizontalalignment='left',\n",
        "                    verticalalignment='top', transform=ax.transAxes, size='large')\n",
        "\n",
        "ax.set_ylabel('Membrane Potential ($u$)')\n",
        "ax.set_xlabel('Time Steps')\n",
        "ax.plot(target_mem[:, 0, 0].cpu().detach().numpy(), label='Target', linestyle='dashed')\n",
        "ax.axhline(y=threshold, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "\n",
        "\n",
        "def animate(frame_num):\n",
        "    line.set_data(x, mem_avg_bin[frame_num, x, 0,0])\n",
        "    time_text.set_text(f'Epoch: {frame_num}')\n",
        "\n",
        "    # ax.plot([], [], ' ', label=str(frame_num))\n",
        "    # ax.legend(loc='upper right')\n",
        "    return (line, time_text)\n",
        "\n",
        "anim = FuncAnimation(fig, animate, frames=num_epochs, interval=30)\n",
        "anim.save('spk_time_bin_MVA.mp4', fps=25, extra_args=['-vcodec', 'libx264'], dpi=300)\n",
        "\n",
        "video = anim.to_html5_video()\n",
        "html = display.HTML(video)\n",
        "display.display(html)\n",
        "plt.close()                   # avoid plotting a spare static plot"
      ],
      "metadata": {
        "id": "vMwX-33biqey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perhaps not."
      ],
      "metadata": {
        "id": "zGS39QO9vf5L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lakzDLwG8K5"
      },
      "source": [
        "# 3. Wide threshold BNN\n",
        "If we use a large threshold, then each spiking neuron would have a wider dynamic range state-space, and this could enable more precise tuning. \n",
        "\n",
        "The problem we will run into is, if the threshold is too high, then downstream spikes probably won't occur, and so learning will also fail to take place. Let's set the threhsold of all neurons to $\\theta=50$. This is a significant jump from $\\theta=1$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqAGq-h1pIe5"
      },
      "source": [
        "## 3.1 Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB_7CDHhWqb_"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "dtype = torch.float\n",
        "num_steps = 100\n",
        "num_inputs = 100\n",
        "num_hidden = 1000\n",
        "batch_size = 1\n",
        "beta=0.15\n",
        "w_thr1 = 50\n",
        "w_thr2 = 50  # 25 works well\n",
        "on_target = w_thr2 + w_thr2*0.1\n",
        "first_spike_time = 75\n",
        "\n",
        "loss_fn = nn.MSELoss() \n",
        "# loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUkd2Y6MpAg2"
      },
      "source": [
        "## 3.2 Define target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT-ZdMAJbr6K"
      },
      "source": [
        "targets_wthr = spikegen.targets_latency(torch.zeros(1, dtype=dtype, device=device), num_classes=1, first_spike_time=first_spike_time, on_target=on_target, num_steps=num_steps, interpolate=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aTkUWNBpLSs"
      },
      "source": [
        "## 3.3 Define network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suVpw-rm9DKa"
      },
      "source": [
        "wthr_net = nn.Sequential(\n",
        "    BinaryLinear(num_inputs, num_hidden),\n",
        "    snn.Leaky(beta=beta, threshold=w_thr1, spike_grad=surrogate.fast_sigmoid(slope=5), init_hidden=True),\n",
        "    BinaryLinear(num_hidden, 1),\n",
        "    snn.Leaky(beta=beta, threshold=w_thr2, spike_grad=surrogate.fast_sigmoid(slope=5), init_hidden=True, output=True)\n",
        ").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3UEhuiqpM4T"
      },
      "source": [
        "## 3.4 Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6LqaEDKHElP"
      },
      "source": [
        "optimizer = torch.optim.SGD(wthr_net.parameters(), lr=1e-3, momentum=0.9)\n",
        "num_epochs = 1000\n",
        "mem_tot_wthr = []\n",
        "spk_tot_wthr = []\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  mem_rec = []\n",
        "  spk_rec = []\n",
        "\n",
        "  utils.reset(net)\n",
        "\n",
        "  for step in range(num_steps):\n",
        "    spk, mem = wthr_net(input_data[step])\n",
        "    mem_rec.append(mem)\n",
        "    spk_rec.append(spk)\n",
        "\n",
        "  spk_rec = torch.stack(spk_rec)\n",
        "  mem_rec = torch.stack(mem_rec)\n",
        "  spk_tot_wthr.append(spk_rec)\n",
        "  mem_tot_wthr.append(mem_rec)\n",
        "\n",
        "  loss = loss_fn(targets_wthr, mem_rec)\n",
        "\n",
        "  # clear previously stored gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # calculate the gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # weight update\n",
        "  optimizer.step()\n",
        "\n",
        "mem_tot_wthr = torch.stack(mem_tot_wthr)\n",
        "spk_tot_wthr = torch.stack(spk_tot_wthr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 Plot Membrane Potential"
      ],
      "metadata": {
        "id": "k9aHG9Olv1rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_quadrant(mem_tot_wthr, spk_tot_wthr, targets_wthr, spk_target, -1, 60, threshold=50, save=\"spk_time_wthr.png\", epoch1=0, epoch2=75, epoch3=750, fill=True) # save=\"spk_time_flt.png\""
      ],
      "metadata": {
        "id": "lp4uJVMnkpDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGttbe8epcvp"
      },
      "source": [
        "## 3.6 Animation of membrane potential\n",
        "\n",
        "This result doesn't fluctuate, but neither does it produce the desired behavior of spiking at the 75th time step - in fact, no spikes at all are produced. \n",
        "\n",
        "The membrane potential staying constant over time indicates the output neuron does not receive any spikes from the previous layer. Rather, it is the bias driving the second layer. The bias slowly increases until it hits roughly the mid-point of the threshold to minimize the overall loss over time.\n",
        "\n",
        "If the bias was removed, the membrane potential would be stuck at zero. So clearly, this doesn't quite work either.\n",
        "\n",
        "Note that the membrane potential falls just short of 25. This can be explained by the final steps of the target being set to 0, which suppresses the overall steady-state response."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 50\n",
        "fig, ax = plt.subplots()\n",
        "line, = ax.plot([])   # A tuple unpacking to unpack the only plot\n",
        "x = np.arange(0, 100, 1) \n",
        "\n",
        "ax.set_xlim(0, num_steps)\n",
        "ax.set_ylim(-1, 60)\n",
        "time_text = ax.text(0.02, 0.98,'',horizontalalignment='left',\n",
        "                    verticalalignment='top', transform=ax.transAxes, size='large')\n",
        "\n",
        "ax.set_ylabel('Membrane Potential ($u$)')\n",
        "ax.set_xlabel('Time Steps')\n",
        "ax.plot(targets_wthr[:, 0, 0].cpu().detach().numpy(), label='Target', linestyle='dashed')\n",
        "ax.axhline(y=threshold, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "\n",
        "\n",
        "def animate(frame_num):\n",
        "    line.set_data(x, mem_tot_wthr[frame_num, x, 0,0].cpu().detach().numpy())\n",
        "    time_text.set_text(f'Epoch: {frame_num}')\n",
        "\n",
        "    # ax.plot([], [], ' ', label=str(frame_num))\n",
        "    # ax.legend(loc='upper right')\n",
        "    return (line, time_text)\n",
        "\n",
        "anim = FuncAnimation(fig, animate, frames=num_epochs, interval=30)\n",
        "anim.save('spk_time_wthr.mp4', fps=25, extra_args=['-vcodec', 'libx264'], dpi=300)\n",
        "\n",
        "video = anim.to_html5_video()\n",
        "html = display.HTML(video)\n",
        "display.display(html)\n",
        "plt.close()                   # avoid plotting a spare static plot"
      ],
      "metadata": {
        "id": "lNN-KZ_Yk620"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoGgy9igi5WE"
      },
      "source": [
        "# 4. Bounded Homeostasis\n",
        "## 4.1 Define Threshold Annealing Function\n",
        "\n",
        "If we slowly anneal the threshold from a small value to a larger value, this will result in strong spiking activity in early epochs which avoids the dead neuron problem we saw in the previous case where $\\theta=50$.\n",
        "\n",
        "We implement the most naive form of bounded homeostasis (i.e., one that does not depend on the weight update gradient as with other experiments, which can simply referred to as `threshold annealing') below with exponential relaxation of threshold toward a steady state, completely independent of the input data. The same threshold is applied to all neurons in all layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfrH7cqSjEs3"
      },
      "source": [
        "def thr_annealing(conf, network):\n",
        "    alpha_thr1 = conf['alpha_thr1']\n",
        "    alpha_thr2 = conf['alpha_thr2']\n",
        "\n",
        "    thr_final1 = conf['thr_final1']\n",
        "    thr_final2 = conf['thr_final2']\n",
        "\n",
        "    with torch.no_grad():\n",
        "      network.lif1.threshold += (thr_final1 - network.lif1.threshold) * alpha_thr1\n",
        "      network.lif2.threshold += (thr_final2 - network.lif2.threshold) * alpha_thr2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7KBgUEFqQEb"
      },
      "source": [
        "## 4.2 Define Hyperparameters\n",
        "As before, we set the final threshold to 50. But let's start with 5.0, and gradually warm it up to 50. `alpha_thr1` and `alpha_thr2` are the inverse time constants of the threshold evolution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV-iBTtCjTAV"
      },
      "source": [
        "config = {\n",
        "    \n",
        "    'thr_init1' : 5.0,\n",
        "    'thr_init2' : 5.0,\n",
        "\n",
        "    'alpha_thr1' : 5e-3,\n",
        "    'alpha_thr2' : 5e-3,\n",
        "\n",
        "    'thr_final1' : 50.0,\n",
        "    'thr_final2' : 50.0,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99WfOLJWXsop"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "dtype = torch.float\n",
        "num_steps = 100\n",
        "num_inputs = 100\n",
        "num_hidden = 1000\n",
        "batch_size = 1\n",
        "beta=0.15\n",
        "on_target = config['thr_final2'] + config['thr_final2']*0.1\n",
        "\n",
        "loss_fn = nn.MSELoss() \n",
        "# loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hCzxrlbqmS5"
      },
      "source": [
        "## 4.3 Define Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8T0SawYc3vI"
      },
      "source": [
        "targets_tha = spikegen.targets_latency(torch.zeros(1, dtype=dtype, device=device), num_classes=1, first_spike_time=75, on_target=on_target, num_steps=num_steps, interpolate=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CBSUwJxYjaU"
      },
      "source": [
        "## 4.4 Define network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upUaiEzci-Dk"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    beta = 0.15\n",
        "    spike_grad = surrogate.fast_sigmoid(slope=5)\n",
        "\n",
        "    self.fc1 = BinaryLinear(num_inputs, num_hidden)\n",
        "    self.fc2 = BinaryLinear(num_hidden, 1)\n",
        "\n",
        "    self.lif1 = snn.Leaky(beta=beta, threshold=config['thr_init1'], spike_grad = spike_grad)\n",
        "    self.lif2 = snn.Leaky(beta=beta, threshold=config['thr_init2'], spike_grad=spike_grad)\n",
        "\n",
        "  def forward(self, x):\n",
        "    mem1 = self.lif1.init_leaky() \n",
        "    mem2 = self.lif2.init_leaky() \n",
        "\n",
        "    spk2_rec = []\n",
        "    mem2_rec = []\n",
        "\n",
        "    for step in range(x.size(0)):\n",
        "      cur1 = self.fc1(x[step])\n",
        "      spk1, mem1 = self.lif1(cur1, mem1)\n",
        "      cur2 = self.fc2(spk1)\n",
        "      spk2, mem2 = self.lif2(cur2, mem2)\n",
        "\n",
        "      spk2_rec.append(spk2)\n",
        "      mem2_rec.append(mem2)\n",
        "    \n",
        "    return torch.stack(spk2_rec), torch.stack(mem2_rec)\n",
        "\n",
        "net_tha = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqMrSdqrq0mW"
      },
      "source": [
        "## 4.5 Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS-4Wn10jA6d"
      },
      "source": [
        "optimizer = torch.optim.SGD(net_tha.parameters(), lr=1e-3, momentum=0.9)\n",
        "num_epochs = 1000\n",
        "mem_tot_tha = []\n",
        "spk_tot_tha = []\n",
        "thr_L1 = []\n",
        "thr_L2 = []\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "\n",
        "  spk_rec, mem_rec = net_tha(input_data)\n",
        "  spk_tot_tha.append(spk_rec)\n",
        "  mem_tot_tha.append(mem_rec)\n",
        "  loss = loss_fn(targets_tha, mem_rec)\n",
        "\n",
        "  # clear previously stored gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # calculate the gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # weight update\n",
        "  optimizer.step()\n",
        "\n",
        "  thr_L1.append(net_tha.lif1.threshold.item())\n",
        "  thr_L2.append(net_tha.lif2.threshold.item())\n",
        "\n",
        "  thr_annealing(config, net_tha)\n",
        "  \n",
        "\n",
        "mem_tot_tha = torch.stack(mem_tot_tha)\n",
        "spk_tot_tha = torch.stack(spk_tot_tha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8L8DJ7aq4Ov"
      },
      "source": [
        "## 4.6 Plot Membrane Potential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_quadrant_tha(mem_tot_tha, spk_tot_tha, targets_tha, spk_target, -1, 60, threshold=thr_L1, save=\"spk_time_tha.png\", epoch1=0, epoch2=100, epoch3=400, fill=True) # save=\"spk_time_flt.png\""
      ],
      "metadata": {
        "id": "n166WYwtnBIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thr_L1[400]"
      ],
      "metadata": {
        "id": "7YQULZmjhbhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is looking quite nice as training progresses! Let's see the animated version to get better insight."
      ],
      "metadata": {
        "id": "x0Hr_q2Pxipv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.7 Animation of Membrane Potential"
      ],
      "metadata": {
        "id": "4bAvxJ92xe7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 50\n",
        "fig, ax = plt.subplots()\n",
        "line, = ax.plot([])   # A tuple unpacking to unpack the only plot\n",
        "thr_line, = ax.plot([])\n",
        "thr_text1 = ax.text(0.98, 0.91,'',horizontalalignment='right',verticalalignment='top', transform=ax.transAxes, size='large')\n",
        "x = np.arange(0, 100, 1) \n",
        "\n",
        "ax.set_xlim(0, num_steps)\n",
        "ax.set_ylim(-1, 60)\n",
        "time_text = ax.text(0.02, 0.98,'',horizontalalignment='left',\n",
        "                    verticalalignment='top', transform=ax.transAxes, size='large')\n",
        "\n",
        "ax.set_ylabel('Membrane Potential ($u$)')\n",
        "ax.set_xlabel('Time Steps')\n",
        "ax.plot(targets_tha[:, 0, 0].cpu().detach().numpy(), label='Target', linestyle='dashed')\n",
        "ax.axhline(y=threshold, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "\n",
        "\n",
        "def animate(frame_num):\n",
        "    line.set_data(x, mem_tot_tha[frame_num, x, 0,0].cpu().detach().numpy())\n",
        "    thr_line.set_data(x, thr_L1[frame_num])\n",
        "    thr_text1.set_text(f'Threshold: {thr_L1[frame_num]:.3f}')\n",
        "    time_text.set_text(f'Epoch: {frame_num}')\n",
        "\n",
        "    # ax.plot([], [], ' ', label=str(frame_num))\n",
        "    # ax.legend(loc='upper right')\n",
        "    return (line, time_text, thr_text1)\n",
        "\n",
        "anim = FuncAnimation(fig, animate, frames=num_epochs, interval=30) # num_epochs\n",
        "anim.save('spk_time_tha.mp4', fps=25, extra_args=['-vcodec', 'libx264'], dpi=300)\n",
        "\n",
        "video = anim.to_html5_video()\n",
        "html = display.HTML(video)\n",
        "display.display(html)\n",
        "plt.close()                   # avoid plotting a spare static plot"
      ],
      "metadata": {
        "id": "xTqE4_2TnV8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To begin with, the several spikes trigger a sudden explosion in activity as the neuron tries to climb its way to $u=50$. Sensory overload. \n",
        "\n",
        "But as the threshold warms up further, activity becomes sparser until finally, the neuron actually hits the desired firing time at several epochs."
      ],
      "metadata": {
        "id": "tIZe7dLiyfwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.8 Moving Average of Membrane"
      ],
      "metadata": {
        "id": "PPckpEvxrn8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 50\n",
        "fig, ax = plt.subplots()\n",
        "line, = ax.plot([])   # A tuple unpacking to unpack the only plot\n",
        "thr_line, = ax.plot([])\n",
        "thr_text1 = ax.text(0.98, 0.91,'',horizontalalignment='right',verticalalignment='top', transform=ax.transAxes, size='large')\n",
        "x = np.arange(0, 100, 1) \n",
        "\n",
        "\n",
        "N = 5 # size of filter\n",
        "mem_avg_tha = uniform_filter1d(mem_tot_tha.cpu().detach(), size=N, axis=1)\n",
        "\n",
        "ax.set_xlim(0, num_steps)\n",
        "ax.set_ylim(-1, 60)\n",
        "time_text = ax.text(0.02, 0.98,'',horizontalalignment='left',\n",
        "                    verticalalignment='top', transform=ax.transAxes, size='large')\n",
        "\n",
        "ax.set_ylabel('Membrane Potential ($u$)')\n",
        "ax.set_xlabel('Time Steps')\n",
        "ax.plot(targets_tha[:, 0, 0].cpu().detach().numpy(), label='Target', linestyle='dashed')\n",
        "ax.axhline(y=threshold, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "\n",
        "\n",
        "def animate(frame_num):\n",
        "    line.set_data(x, mem_avg_tha[frame_num, x, 0,0])\n",
        "    thr_line.set_data(x, thr_L1[frame_num])\n",
        "    thr_text1.set_text(f'Threshold: {thr_L1[frame_num]:.3f}')\n",
        "    time_text.set_text(f'Epoch: {frame_num}')\n",
        "\n",
        "    # ax.plot([], [], ' ', label=str(frame_num))\n",
        "    # ax.legend(loc='upper right')\n",
        "    return (line, time_text, thr_text1)\n",
        "\n",
        "anim = FuncAnimation(fig, animate, frames=num_epochs, interval=30) # num_epochs\n",
        "anim.save('spk_time_tha_MVA.mp4', fps=25, extra_args=['-vcodec', 'libx264'], dpi=300)\n",
        "\n",
        "video = anim.to_html5_video()\n",
        "html = display.HTML(video)\n",
        "display.display(html)\n",
        "plt.close()                   # avoid plotting a spare static plot"
      ],
      "metadata": {
        "id": "je3u03vKrncP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H4v8Augr4wO"
      },
      "source": [
        "Not only do we see learning taking place, but the values chosen are completely arbitary. When writing this notebook, this was the first result we obtained. It is likely something more precise could be obtained by choosing layer-independent thresholds & annealing rates."
      ]
    }
  ]
}